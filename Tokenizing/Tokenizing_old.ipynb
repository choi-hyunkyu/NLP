{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KoNLPy 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt, Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "komoran = Komoran()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '안녕하세요! 저는~ 소프트웨어융합대학 인공지능전공 최현규입니다>_<7 지금 자연어처리를 공부중입니다.!@#$%^&*`~'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규표현식을 위한 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특수 문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = re.sub('[-_=+,0-9#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요 저는 소프트웨어융합대학 인공지능전공 최현규입니다 지금 자연어처리를 공부중입니다\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화(조사/어미)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text_1 = okt.pos(cleaned_text)\n",
    "tokenized_text_2 = komoran.pos(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoNLPy Okt Tokenizer result\n",
      "\n",
      "[('안녕하세요', 'Adjective'), ('저', 'Noun'), ('는', 'Josa'), ('소프트웨어', 'Noun'), ('융합', 'Noun'), ('대학', 'Noun'), ('인공', 'Noun'), ('지능', 'Noun'), ('전공', 'Noun'), ('최현', 'Noun'), ('규', 'Noun'), ('입니다', 'Adjective'), ('지금', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('를', 'Josa'), ('공부', 'Noun'), ('중', 'Suffix'), ('입니다', 'Adjective')]\n"
     ]
    }
   ],
   "source": [
    "print(\"KoNLPy Okt Tokenizer result\")\n",
    "print()\n",
    "print(tokenized_text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoNLPy Komoran Tokenizer result\n",
      "\n",
      "[('안녕하세요', 'NNP'), ('저', 'NP'), ('는', 'JX'), ('소프트웨어', 'NNG'), ('융합', 'NNG'), ('대학', 'NNG'), ('인공지능', 'NNP'), ('전공', 'NNG'), ('최현', 'NNP'), ('규', 'NNG'), ('이', 'VCP'), ('ㅂ니다', 'EC'), ('지금', 'MAG'), ('자연어', 'NNP'), ('처리', 'NNG'), ('를', 'JKO'), ('공부', 'NNP'), ('중', 'NNB'), ('이', 'VCP'), ('ㅂ니다', 'EC')]\n"
     ]
    }
   ],
   "source": [
    "print(\"KoNLPy Komoran Tokenizer result\")\n",
    "print()\n",
    "print(tokenized_text_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '먹고는'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = okt.pos(test) # okt tokenizer\n",
    "result_2 = komoran.pos(test) # komoran tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoNLPy Okt Tokenizer result: [('먹고는', 'Verb')]\n",
      "KoNLPy Komoran Tokenizer result: [('먹', 'VV'), ('고', 'EC'), ('는', 'JX')]\n"
     ]
    }
   ],
   "source": [
    "print(\"KoNLPy Okt Tokenizer result:\", result_1)\n",
    "print(\"KoNLPy Komoran Tokenizer result:\", result_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
