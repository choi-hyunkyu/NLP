{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "모듈 임포트\n",
    "'''\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "데이터 로딩\n",
    "'''\n",
    "\n",
    "def read_data(address_1, address_2):\n",
    "    data_1 = []\n",
    "    with open(address_1, 'r') as file:\n",
    "        document = file.readlines()\n",
    "        for sentence in document:\n",
    "            sentence = sentence.strip('\\n').strip()\n",
    "            if len(sentence) > 1:\n",
    "                try:\n",
    "                    data_1.append(sentence)\n",
    "                except:\n",
    "                    del sentence\n",
    "\n",
    "    data_2 = []\n",
    "    with open(address_2, 'r') as file:\n",
    "        document = file.readlines()\n",
    "        for sentence in document:\n",
    "            sentence = sentence.strip('\\n').strip()\n",
    "            if len(sentence) > 1:\n",
    "                try:\n",
    "                    data_2.append(sentence)\n",
    "                except:\n",
    "                    del sentence\n",
    "                    \n",
    "    return data_1, data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_1 = './data/document_1.txt'\n",
    "address_2 = './data/document_2.txt'\n",
    "\n",
    "data_1, data_2 = read_data(address_1, address_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['검찰, ‘물고문’ 여부 집중조사', '‘피의자 사망사건’을 조사중인 대검 감찰부(박태종 검사장)는 1일 물고문 의혹과 관련, 검찰 조사과정에서 ‘물고문’을 당했다고 주장한 조모씨의 공범 박모(구속)씨와 물고문 협박을 당했다는 참고인 박모씨를 소환, 물고문이 실제 이뤄졌는지를 집중 조사중이다.', '검찰은 공범 박씨가 영장실질심사 과정 등에서 \"수사관들이 내 얼굴에 수건을 덮어 씌우고 물을 붓는 등 사실상 물고문을 했다\"고 거듭 주장함에 따라 당시의 구체적 정황을 캐는데 주력하고 있다.', '검찰은 이날 구속된 수사관 3명을 소환, 필요할 경우 박씨 등과 대질조사도 벌일 방침인 것으로 알려졌다.', '검찰은 그러나 전날 정모씨 등 다른 공범 2명을 조사한 결과 물고문 주장이 없었고, 구속된 수사관 3명도 모두 물고문 의혹을 완강히 부인하고 있다고 전했다.', '검찰 관계자는 \"관련자 진술 등 여러 가지 정황에 비춰볼 때 박씨 등의 물고문 관련 진술은 신빙성이 낮아 보이지만 박씨 등이 물고문 주장을 굽히지 않고 있는 만큼 의혹해소 차원에서 진위를 조사할 것\"이라고 말했다.', '한편 검찰은 숨진 조모씨의 자해행위를 놓고 구속된 수사관들의 진술이 엇갈림에 따라 조씨가 자해보다는 구타로 인해 사망했을 가능성이 있다고 보고 구속된 수사관들을 추궁키로 했다.', '검찰은 또 전날 사무실에서 ‘머리가 어지럽다’며 병원으로 후송된 홍모 검사의 건강상태가 호전될 경우 이날 중 재소환, 조사키로 했다.', '홍 검사는 극심한 육체적, 정신적 스트레스로 인해 탈진해 병원에서 링거를 맞고 있으며, 의료진으로부터 ‘절대안정’이 필요하다는 진단을 받은 것으로 알려졌다.']\n",
      "<class 'list'> 9\n"
     ]
    }
   ],
   "source": [
    "print(data_1)\n",
    "print(type(data_1), len(data_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"검찰 '물고문' 의혹 현장검증\", '서울지검, 정밀감정 의로키로', '공범 박씨등-수사관 대질조사', \"`피의자 사망사건'을 조사중인 대검 감찰부(박태종 검사장)는 1일 `물고문' 의혹과 관련, 서울지검 청사 11층 특별조사실에 대한 현장검증을 전날 밤 실시, 집기 등을 수거했으며 정밀감정을 의뢰키로 했다고 밝혔다.\", '주요 감정 대상에는 특조실에 비치된 수건과 주전자, 카펫을 비롯, 피의자들이 입고 있던 옷, 욕조 등이 포함된 것으로 알려졌다.', \"검찰은 숨진 조모씨가 지난달 26일 조사를 받은 특조실에서 `그만 때려라'는 등 가혹행위를 연상시키는 소리를 들었고 물고문 협박을 받았다고 주장한 박모.김모씨와 물고문을 당했다고 주장한 살인사건 공범 박모(구속)씨 등을 이날 소환, 당시의 구체적인 정황을 조사중이다.\", '검찰은 조씨를 상대로 밤샘조사를 벌인 뒤 지난 26일 낮 12시께 수사관들이 휴식을 취하던 조씨를 깨운 당시에도 구타 등 가혹행위를 했다는 관련자 진술을 확보, 수사관들을 불러 진위를 캐고 있다.', '검찰은 구속된 수사관 3명과 살인사건 공범 박씨 등을 대질, 물고문 등 가혹행위 여부 등을 조사중이다.', '검찰은 그러나 전날 정모씨 등 다른 공범 2명을 조사한 결과 물고문 관련 진술이 없었고, 구속된 수사관 3명도 모두 물고문 의혹을 완강히 부인하고 있다고 말했다.', \"검찰은 또 전날 사무실에서 `어지럽다'며 병원으로 후송된 홍모 검사를 이날 재소환, 조씨를 직접 조사할 때 가혹행위 등을 알고 있었는지 또는 가혹행위를 묵인.방조했는지 여부 등을 조사키로 했다.\", '검찰 관계자는 \"물고문이란게 사회 통념상 욕조 설비가 전제되는 행위로 봐야되는 것 아니냐\"며 \"그러나 수건을 이용해 물고문을 했다는 의혹이 제기된 만큼 사실 관계를 명확히 규명하고 있다\"고 말했다.', '한편 검찰은 숨진 조씨의 자해행위 여부를 놓고 구속된 수사관들의 진술이 엇갈림에 따라 조씨가 자해보다는 구타로 인해 사망했을 가능성이 높다고 보고 구속된 수사관들을 추궁중이다.', '검찰은 2일중 국립과학수사연구소로부터 조씨에 대한 정밀 조직검사 등 부검 결과를 넘겨받는 대로 가혹행위에 의한 사망여부 등을 결론낼 방침이다.', '국과수는 이와 관련, 조씨가 외부 충격에 의한 뇌출혈 등으로 사망했고 구타 행위 등 가혹행위가 있었을 가능성을 배제하지 않는다고 잠정결론지은 것으로 전해졌다.']\n",
      "<class 'list'> 14\n"
     ]
    }
   ],
   "source": [
    "print(data_2)\n",
    "print(type(data_2), len(data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "vectorizing 함수 정의\n",
    "'''\n",
    "def vectorizing(data):\n",
    "    \n",
    "    # CountVectorizer() 함수 선언\n",
    "    cv = CountVectorizer()\n",
    "    \n",
    "    # 문자열 결함\n",
    "    concatenated_data = [\" \".join(data)]\n",
    "    \n",
    "    # data vectorizing\n",
    "    vectorized_data = cv.fit_transform(concatenated_data)\n",
    "    vectorized_data = vectorized_data\n",
    "    \n",
    "    # 단어사전 변수 저장\n",
    "    vocab = cv.get_feature_names()\n",
    "    \n",
    "    return vectorized_data, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "vectorizing 계산\n",
    "'''\n",
    "\n",
    "vectorized_data_1, vocab_1 = vectorizing(data_1)\n",
    "vectorized_data_2, vocab_2 = vectorizing(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12)\t3\n",
      "  (0, 49)\t8\n",
      "  (0, 91)\t1\n",
      "  (0, 136)\t1\n",
      "  (0, 142)\t1\n",
      "  (0, 68)\t1\n",
      "  (0, 120)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 57)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 96)\t1\n",
      "  (0, 20)\t2\n",
      "  (0, 118)\t1\n",
      "  (0, 33)\t1\n",
      "  (0, 128)\t1\n",
      "  (0, 117)\t2\n",
      "  (0, 17)\t3\n",
      "  (0, 53)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 83)\t1\n",
      "  (0, 147)\t1\n",
      "  (0, 34)\t1\n",
      "  (0, 138)\t1\n",
      "  :\t:\n",
      "  (0, 47)\t1\n",
      "  (0, 86)\t1\n",
      "  (0, 62)\t1\n",
      "  (0, 150)\t1\n",
      "  (0, 149)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 148)\t1\n",
      "  (0, 109)\t1\n",
      "  (0, 121)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 28)\t1\n",
      "  (0, 94)\t1\n",
      "  (0, 114)\t1\n",
      "  (0, 79)\t1\n",
      "  (0, 141)\t1\n",
      "  (0, 61)\t1\n",
      "  (0, 43)\t1\n",
      "  (0, 46)\t1\n",
      "  (0, 106)\t1\n",
      "  (0, 95)\t1\n",
      "  (0, 112)\t1\n",
      "  (0, 143)\t1\n",
      "  (0, 130)\t1\n",
      "  (0, 58)\t1 | data1 shape:  (1, 151)\n",
      "['1일', '2명을', '3명도', '3명을', '가능성이', '가지', '감찰부', '거듭', '건강상태가', '검사는', '검사의', '검사장', '검찰', '검찰은', '것으로', '결과', '경우', '공범', '과정', '관계자는', '관련', '관련자', '구속', '구속된', '구체적', '구타로', '굽히지', '그러나', '극심한', '낮아', '놓고', '다른', '당시의', '당했다고', '당했다는', '대검', '대질조사도', '덮어', '등과', '등에서', '등의', '등이', '따라', '링거를', '만큼', '말했다', '맞고', '머리가', '모두', '물고문', '물고문을', '물고문이', '물을', '박모', '박모씨를', '박씨', '박씨가', '박태종', '받은', '방침인', '벌일', '병원에서', '병원으로', '보고', '보이지만', '부인하고', '붓는', '비춰볼', '사망사건', '사망했을', '사무실에서', '사실상', '소환', '수건을', '수사관', '수사관들을', '수사관들의', '수사관들이', '숨진', '스트레스로', '신빙성이', '실제', '씌우고', '씨와', '않고', '알려졌다', '어지럽다', '얼굴에', '없었고', '엇갈림에', '여러', '여부', '영장실질심사', '완강히', '육체적', '의료진으로부터', '의혹과', '의혹을', '의혹해소', '이날', '이라고', '이뤄졌는지를', '인해', '있는', '있다', '있다고', '있으며', '자해보다는', '자해행위를', '재소환', '전날', '전했다', '절대안정', '정모씨', '정신적', '정황에', '정황을', '조모씨의', '조사과정에서', '조사중이다', '조사중인', '조사키로', '조사한', '조사할', '조씨가', '주력하고', '주장을', '주장이', '주장한', '주장함에', '진단을', '진술', '진술은', '진술이', '진위를', '집중', '집중조사', '차원에서', '참고인', '추궁키로', '캐는데', '탈진해', '피의자', '필요하다는', '필요할', '한편', '했다', '협박을', '호전될', '홍모', '후송된'] | vocab1 length:  151\n",
      "-----------\n",
      "  (0, 18)\t2\n",
      "  (0, 67)\t6\n",
      "  (0, 128)\t1\n",
      "  (0, 196)\t1\n",
      "  (0, 99)\t2\n",
      "  (0, 151)\t1\n",
      "  (0, 125)\t1\n",
      "  (0, 24)\t4\n",
      "  (0, 72)\t1\n",
      "  (0, 106)\t3\n",
      "  (0, 53)\t1\n",
      "  (0, 188)\t1\n",
      "  (0, 90)\t1\n",
      "  (0, 158)\t1\n",
      "  (0, 49)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 73)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 129)\t1\n",
      "  (0, 27)\t3\n",
      "  (0, 177)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 184)\t1\n",
      "  (0, 54)\t2\n",
      "  :\t:\n",
      "  (0, 166)\t1\n",
      "  (0, 85)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 41)\t1\n",
      "  (0, 50)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 127)\t2\n",
      "  (0, 91)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 79)\t1\n",
      "  (0, 34)\t1\n",
      "  (0, 133)\t1\n",
      "  (0, 123)\t1\n",
      "  (0, 179)\t1\n",
      "  (0, 44)\t1\n",
      "  (0, 56)\t1\n",
      "  (0, 92)\t1\n",
      "  (0, 194)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 141)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 80)\t1\n",
      "  (0, 113)\t1\n",
      "  (0, 144)\t1\n",
      "  (0, 148)\t1 | data2 shape (1, 203)\n",
      "['11층', '12시께', '1일', '26일', '2명을', '2일중', '3명과', '3명도', '가능성을', '가능성이', '가혹행위', '가혹행위가', '가혹행위를', '가혹행위에', '감정', '감찰부', '검사를', '검사장', '검찰', '검찰은', '것으로', '결과', '결과를', '결론낼', '공범', '관계를', '관계자는', '관련', '관련자', '구속', '구속된', '구체적인', '구타', '구타로', '국과수는', '국립과학수사연구소로부터', '규명하고', '그러나', '그만', '김모씨와', '깨운', '넘겨받는', '높다고', '놓고', '뇌출혈', '다른', '당시에도', '당시의', '당했다고', '대검', '대로', '대상에는', '대질', '대질조사', '대한', '들었고', '등으로', '등을', '등이', '따라', '때려라', '또는', '만큼', '말했다', '명확히', '모두', '묵인', '물고문', '물고문을', '물고문이란게', '박모', '박씨', '박씨등', '박태종', '받았다고', '받은', '밝혔다', '밤샘조사를', '방조했는지', '방침이다', '배제하지', '벌인', '병원으로', '보고', '봐야되는', '부검', '부인하고', '불러', '비롯', '비치된', '사망사건', '사망여부', '사망했고', '사망했을', '사무실에서', '사실', '사회', '살인사건', '상대로', '서울지검', '설비가', '소리를', '소환', '수거했으며', '수건과', '수건을', '수사관', '수사관들을', '수사관들의', '수사관들이', '숨진', '실시', '아니냐', '않는다고', '알고', '알려졌다', '어지럽다', '없었고', '엇갈림에', '여부', '여부를', '연상시키는', '완강히', '외부', '욕조', '의로키로', '의뢰키로', '의한', '의혹', '의혹과', '의혹을', '의혹이', '이날', '이와', '이용해', '인해', '입고', '있다', '있다고', '있던', '있었는지', '있었을', '자해보다는', '자해행위', '잠정결론지은', '재소환', '전날', '전제되는', '전해졌다', '정모씨', '정밀', '정밀감정', '정밀감정을', '정황을', '제기된', '조모씨가', '조사를', '조사중이다', '조사중인', '조사키로', '조사한', '조사할', '조씨가', '조씨를', '조씨에', '조씨의', '조직검사', '주요', '주장한', '주전자', '지난', '지난달', '직접', '진술을', '진술이', '진위를', '집기', '청사', '추궁중이다', '충격에', '취하던', '카펫을', '캐고', '통념상', '특별조사실에', '특조실에', '특조실에서', '포함된', '피의자', '피의자들이', '한편', '했다', '했다고', '했다는', '행위', '행위로', '현장검증', '현장검증을', '협박을', '홍모', '확보', '후송된', '휴식을'] | vocab2 length:  203\n"
     ]
    }
   ],
   "source": [
    "print(vectorized_data_1, \"| data1 shape: \", vectorized_data_1.shape)\n",
    "print(vocab_1, \"| vocab1 length: \", len(vocab_1))\n",
    "print(\"-----------\")\n",
    "print(vectorized_data_2, \"| data2 shape\", vectorized_data_2.shape)\n",
    "print(vocab_2, \"| vocab2 length: \", len(vocab_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "코사인 유사도 계산 함수 정의\n",
    "'''\n",
    "def cal_cosine_sim(data_1, data_2):\n",
    "    \n",
    "    tfidf_trans = TfidfTransformer()\n",
    "    \n",
    "    vectorized_data_1, _ = vectorizing(data_1)\n",
    "    vectorized_data_2, _ = vectorizing(data_2)\n",
    "    \n",
    "    transformed_data_1 = tfidf_trans.fit_transform(vectorized_data_1).toarray()\n",
    "    transformed_data_2 = tfidf_trans.fit_transform(vectorized_data_2).toarray()\n",
    "    \n",
    "    x_1, y_1 = transformed_data_1.shape\n",
    "    x_2, y_2 = transformed_data_2.shape\n",
    "    \n",
    "    lows_length_list = [x_1, x_2]\n",
    "    columns_length_list = [y_1, y_2]\n",
    "    \n",
    "    max_lows_length = max(lows_length_list)\n",
    "    max_columns_length = max(columns_length_list)\n",
    "    \n",
    "    # padding\n",
    "    if x_1 < max_columns_length:\n",
    "        try:\n",
    "            transformed_data_1 = np.pad(transformed_data_1, \n",
    "                                        ((0, 0), (0, int(max_columns_length - y_1))), \n",
    "                                        mode='constant', \n",
    "                                        constant_values=0\n",
    "                                       )\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if x_2 < max_columns_length:\n",
    "        try:\n",
    "            transformed_data_2 = np.pad(transformed_data_2, \n",
    "                                        ((0, 0), (0, int(max_columns_length - y_2))),\n",
    "                                        mode='constant', \n",
    "                                        constant_values=0\n",
    "                                       )\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    if y_1 < max_lows_length:\n",
    "        try:\n",
    "            transformed_data_1 = np.pad(transformed_data_1,\n",
    "                                        ((0, int(max_lows_length - x_1)), (0, 0)),\n",
    "                                        mode='constant', \n",
    "                                        constant_values=0\n",
    "                                       )\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    if y_2 < max_lows_length:\n",
    "        try:\n",
    "            transformed_data_2 = np.pad(transformed_data_2, \n",
    "                                        ((0, int(max_lows_length - x_2)), (0, 0)),\n",
    "                                        mode='constant', \n",
    "                                        constant_values=0\n",
    "                                       )\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    similarity = cosine_similarity(transformed_data_1, transformed_data_2)\n",
    "    \n",
    "    return transformed_data_1, transformed_data_2, similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "코사인 유사도 계산\n",
    "'''\n",
    "transformed_data_1, transformed_data_2, similarity = cal_cosine_sim(data_1, data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 203)\n",
      "(1, 203)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "데이터 차원 확인\n",
    "'''\n",
    "\n",
    "print(transformed_data_1.shape)\n",
    "print(transformed_data_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.16744367 0.27907279 0.11162911 0.05581456 0.11162911 0.16744367\n",
      "  0.05581456 0.05581456 0.11162911 0.05581456 0.05581456 0.22325823\n",
      "  0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.11162911 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.44651646 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.16744367 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.11162911 0.05581456 0.11162911 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.11162911 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.11162911 0.05581456 0.05581456\n",
      "  0.11162911 0.05581456 0.05581456 0.11162911 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.11162911 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.11162911 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.05581456 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.05581456 0.16744367 0.05581456 0.05581456 0.05581456\n",
      "  0.05581456 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n",
      "[[0.04583492 0.04583492 0.04583492 0.09166985 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.09166985 0.04583492\n",
      "  0.13750477 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.09166985 0.32084447 0.09166985 0.04583492 0.04583492 0.04583492\n",
      "  0.1833397  0.04583492 0.04583492 0.13750477 0.04583492 0.04583492\n",
      "  0.1833397  0.04583492 0.09166985 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.09166985 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.09166985 0.04583492 0.04583492 0.32084447 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.09166985 0.04583492 0.04583492\n",
      "  0.04583492 0.27500955 0.09166985 0.04583492 0.09166985 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.09166985 0.04583492 0.09166985 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.13750477 0.09166985\n",
      "  0.04583492 0.04583492 0.09166985 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.04583492 0.09166985\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.09166985 0.04583492\n",
      "  0.04583492 0.09166985 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.09166985 0.04583492 0.04583492 0.04583492 0.04583492 0.09166985\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.13750477 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.09166985 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.09166985 0.13750477 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.09166985 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.09166985 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.09166985 0.04583492 0.04583492 0.04583492 0.04583492\n",
      "  0.04583492 0.04583492 0.04583492 0.04583492 0.04583492]]\n"
     ]
    }
   ],
   "source": [
    "print(transformed_data_1)\n",
    "print(transformed_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "[[0.62933098]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "결과\n",
    "'''\n",
    "print(similarity.shape)\n",
    "print(similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
